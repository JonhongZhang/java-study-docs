1. redis 与 Memecache 有什么区别？ 如何进行选用？
    Memecache在处理请求的时候，是以多线程异步IO的方式，性能优秀，利用多核cp；功能相对简单，使用内存存储数据， 支持key- value的结构，不支持持久化，不支持主从同步，设置失效期，过期则被清除，失效策略使用的延迟失效，当再次使用数据时要检查是否失效，当容量满了时候，会对缓存中的数据进行剔除，除了清除过期的key， 按照lru测略对数据进行移除；其中，对于key的限制不能超过250 个字节，value 不能超过1MB ,key 最大失效时间是30天；

    redis的特点，单线程模式，采用非阻塞的异步处理事件机制，缓存数据内存操作IO,时间不会太长，单线程避免了线程上下文切换的消耗
    redis不止可以做缓存，还可以做Nosql数据库，redis除了key-value 这种数据结构，还支持，list, set, sortedSet, hash等；提供主从同步的集群部署能力；
    
2. 你用过redis中的那些数据结构？ 是那些应用场景？
    redis内部使用字典的方式储存数据结构，Redis 支持String, hash, list, set, sorted set这5种数据结构；
        String - 内部是以sds（Simple Dynamic String ）,类似java中的 ArrayList可以预分配冗余空间的方式减少内存的频繁分配；
        List - list内型有ziplist 压缩列表，linkedlist双链表实现，ziplist存储在一片连续的内存上，存储效率高，不利于修改；适合数据较少的情况；
        linkedlist在插入的时候较简单，内存开销比较大，每个节点地址不连续，容易产生内存碎片；在3.2中添加了quickList,是一个双向无环链表，其每一个节点都是一个ziplist。
        hash - redis中，有ziplist与hashtable， 当hash表中，所有的key与value字符串长度都小于64字节，并且键值数量小于512，使用压缩表实现节省空间，超过则使用hashTable;
        set - set类型的内部实现，可以是inset 与 hashtable，当集合中的元素小于512时，且都是数值内型时使用intset , otherwise  it will be used hashTable;
        sorted set - this is an ordered collection, Its implementation has ziplist and skiplist;
            当有序集合中元素数量小于128个，且每个元素长度小于64字节，使用ziplist, 否则就会转成跳表，这是一个转换的过程。
3. redis有哪些持久化方式，区别是什么？
    redis 提供了两种持久化方式，一种是RDB持久化，一种是AOF持久化，
    RBD- 将redis 内存数据库记录定时，dump到磁盘上。
        Redis Server   -------->  fork 子进程
                    |                           child process --- dump到---> RDB 临时文件 
                    |---------->  定时任务                                         ｜
                                                                                覆盖
        我们可以把整个数据库，1. 只包含一个文件，出现灾难性事故，恢复容易；对于灾难恢复，是一个非常好的选择，。2. 可以非常轻松的将一个文件压缩后在转到其他的介子上就可以了。3. 性能最大化上，需要做的是，只需要fork出子进程，在由子进程完成IO的相关操作；4. 相对于AOF 机制如果数据集很大，RDB的启动效率会更高。
        缺点： 如果想保证数据的高可用，最大限度的避免数据的丢失，那么RDB就不是一个很好的选择，系统一但定时持久化之前出现延机现象，那么之前没来的及写入磁盘的数据就会丢失。由于RDB是通过fork 进程的方式，协助数据持久化的工作，当数据集比较大的时候，可能会产生数据库停止1s或者100s的时间；
    AOF - 将Redis 的操作日志以追加的方式写入文件。写、删除、操作会记录，查询操作不会记录；
        Redis Client -----发送写命令-------> Redis Server -----同步写命令-----> AOF记录文件
        1. 数据安全性更高，AOF提供了3种同步策略， 每秒同步，每修改同步，不同步；AOF的实效性是非常高的，每秒与每修改都是非常快的。
            这种方式的在效率上是非常低的； AOF 对于日志文件的写入，使用Apendy（添加）的方式，如果出现延机现象也不会破坏日志文件中存在的内容，如果只写入一半数据就出现系统崩溃的话，也不用担心，redis在下一次启动之前，可以通过redis-check-aof工具解决数据一致性的问题。如果日志文件太大，redis可以开启一个  rewrite机制，redis 以append模式，不断修改数据写入老的磁盘文件中，redis 还会新建一个文件，记录这个时候哪些修改的命令被执行过，因此在执行rewrite切换时更好保障数据的安全性，4. aof 有一个格式比较清晰，容易理解的日志文件，用于记录所有的修改操作，我们也可以通过这些文件完成对数据的重建；
            （BGREWRITEAOF
                    执行一个 AOF文件 重写操作。重写会创建一个当前 AOF 文件的体积优化版本。
                    即使 BGREWRITEAOF 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 BGREWRITEAOF 成功之前不会被修改。
                    重写操作只会在没有其他持久化工作在后台执行时被触发
                    如果 Redis 的子进程正在执行快照的保存工作，那么 AOF 重写的操作会被预定(scheduled)，等到保存工作完成之后再执行 AOF 重写。在这种情况下， BGREWRITEAOF 的返回值仍然是 OK ，但还会加上一条额外的信息，说明 BGREWRITEAOF 要等到保存操作完成之后才能执行。在 Redis 2.6 或以上的版本，可以使用 INFO 命令查看 BGREWRITEAOF 是否被预定。
                    如果已经有别的 AOF 文件重写在执行，那么 BGREWRITEAOF 返回一个错误，并且这个新的 BGREWRITEAOF 请求也不会被预定到下次执行。
                    从 Redis 2.4 开始， AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操作。
                    我都已经3.2.5，貌似redis没有自动触发BGREWRITEAOF
                    算了，还是每天定期的去执行一次
                    写了一个脚本
                    brgewriteaof.sh）
        AOF缺点： 1. AOF 与 RBD在相同数量的数据集，AOF文件大于RDB的文件，RBD 在恢复数据集的时候，比AOF 快很多；
                 2. 根据同步的策略不一样，AOF的运行效率是慢于RDB的
    对比：
        RDB存的是某个时刻的数据快照，采用二进制压缩的方式进行存储的；
        AOF存储的操作命令，采用文本的方式存储的；
        RDB的性能高，AOF性能相对较低，RDB在配置触发状态的时候，还会丢失最后一次快照以及更改的数据；AOF 设置每秒保存一次，最多丢失2秒的数据。
        Redis以主服模式运行时，RDB 不会保存过期的键值对的数据；Redis以从服务器模式运行时，RDB会保存过期的键值对，当主服务器向从服务器同步时，清空过期的键值对。
        AOF 写入文件的时候会对过期的key会追加一条delete命令，当执行aof重写的时候就会忽略过期的key,以及delete命令；
    应用场景： 
        如果redis作为内存数据库，采用AOF与RDB 数据不容易丢失，RDB默认开启；
        如果是作为缓存数据库，使用RDB模式性能更高，一般不建议单独使用aof,性能较差；
        如果使用RDB加AOF，在还原数据则从AOF上还原。
4. redis的过期机制是怎样的，redis 有哪些淘汰策略？
    redis 的过期策略： 定期删除 + 惰性删除；
        所谓定期删除，指默认100ms就会随机抽取一些设置过期的过期时间的key,检查是否过期，如果过期，则删除。 --如果redis中有10万个key有设置过期时间，则会产生问题（没过100ms检查10万个key，cpu过高，redis可能崩溃），实际上是每个100ms随机抽取部分key进行检查删除，那么问题就来了，定期删除会导致，部分key到时间未能进行删除。
        惰性删除：在获取某一个key的时候，判段这个key是否有过期时间，如果有则判断是否过期，过期则删除，不反回。那么问题来了，如果定期删除漏掉了许多过期的key，有些key始终不能进行获取、查，也就不能进行惰性删除，大量过期的key堆积在内存中会导致redis内存块的耗尽。
        走内存淘汰机制： no-eviction 当内存不足时，容纳新写入的数据时，新的写入操作就会报错，几本不用。
                    allkeys-lru: 在键的空间里移除最近最少使用的，常用。
                    allkeys-random: 当内存容纳新写入的数据不足时，键空间随机移除key;
                    volatile-lru: 当内存不足以，容纳新写入的数据时，在设置有过期时间的键空间中，移除最少使用的key；
                    volatile- random: 当内存不足以，容纳新写入的数据时，在设置有过期时间的键空间中，随机移除某一个的key；
                    volatile-ttl: 当内存不足以，容纳新写入的数据时，在设置有过期时间的键空间中，有更早过期时间的key优先移除；
        redis4.0新增了两种，volatile-lfu: 从设置过期时间的key中选择key进行淘汰；
                     allkeys-lfu： 在所有key中进行淘汰； 

        淘汰策略算法：
            FIFO: 先进先出
            LRU: 最近最少使用 (访问的时间) 
            LFU: 最不经常使用，最近最少使用 （访问的频率）

            FIFO: 队列的特点；
            LRU： 根据数据的历史访问记录，进行淘汰；思想是，如果最近该数据被访问过，那么这个数据后续被访问的概率会更高；最新最近被访问的数据放在队列头，
            LFU:  以数据被访问的频率进行淘汰，思想是，如果某一个数据被访问次数很多，则后续被访问的概率更高。
5. 如何保证redis的高并发和高可用？
    redis实现高并发主要是以主从实现，主写，从读；（几万的并发）可以在加个哨兵-实现主备的切换；
    redis集群可以高并发以及容纳更多的数据，（几十万）
6. 如何使用redis的延时队列，如何使用redis的分布式锁？
    延时队列： 在电商系统中，如何定时关闭订单；如何定期检查订单状态，订单是否退款成功；在订单没有长时间没有收到下游系统状态通知的时候，如何实现阶梯式同步订单状态的策略；
    最简单的就是： 定时扫描，扫表，检查过期的订单，来进行主动的关联操作； 优点简单，缺点每分钟需要做全局的扫表，浪费很多资源，如果遇到数据表订单即将过期，以及订单量比较大，会造成订单延时关闭。
    使用rabbitmq或者其他的mq;
    使用redis中的zset list的特性，来实现延时队列

    redis的分布式锁： 使用redis中的set key value nsex,设置进行加锁，命令ever进行解锁，使用jedis set方法帮助加锁的原子性，time out保障不会出现死锁，

7. 什么事缓存的雪崩，缓存穿透，缓存击穿，会造成什么样的问题，如何解决？
    缓存穿透，是指在高并发下查询key不存在的数据会穿过缓存，打到数据库上。针对查询结果为空的情况进行缓存-缓存时间设置短一些，key对应的数据inset 之后清理缓存，不过这个会造成缓存的空值，占用更多的空间。 或者使用BLoom filter在查询时先在过滤器中查询，key是否存在。

    缓存雪崩： 当缓存服务器重启，或者大量key缓存集中失效时，所有的请求到数据库，导致数据库崩溃；解决方案，1. key的失效期，分散开，不同的key设置不同的时间； 2. 设置二级缓存，不一定要数据一致；3.引入高可用，允许数据的脏读，key失效或者redis重启，也可以获得数据，只是数据不一定是最新的数据，根据项目对于实时性要求如何选用；

    缓存击穿： 对于一些设置了过期时间的key,在某些时间超高并发的访问，某些热点数据 ，考虑缓存被击穿，这是针对某个key，缓存在某个时间点过期，刚好在这个时候对于这个key有大量并发请求，这个时候发现缓存过期，一般回从后端DB加载数据，重新设置缓存，这个时候大量并发可能瞬间压垮后台；解决方案： 1. 使用分布式锁的方式，来控制访问线程，setnx互斥锁，进行判断，其他线程处于等待状态，不让大量并发操作数据；2. 不设置过期时间，过期失效的策略为volatile-lru，这样会造成写一致性的问题，当数据库中数据发生更新的时候，缓存中数据不能及时更新，导致数据不一致，应用会获得缓存中的脏数据，通过延时双删的方式解决；

8. 什么是大key，什么事热key，会造成什么问题，如何解决？
    大key，指的是存储的值非常的大；如： 热门话题讨论数据量很大，大V的粉丝列表，序列话的图片，没有及时处理的垃圾数据都会产生大的值
    影响： 大key会占用很大的内存，在集群中无法进行均衡，redis性能下降它会从主从复制中产生异常，在主动删除，过期删除时，操作时间的过程，会导致redis服务阻塞；
    如何发现大key，通过rdb
    如何优化，String 减少长度， list hash set zset--减少成员数，String内型的大key，尽量不用存入redis，可以使用文档型数据库或者mongoDB, cdn上单独存储，不要和其他key在一起，一主一丛，或者多从的方式； 对于当value很大时候，将其拆分文几个key对于的value，将操作压力分到多次操作，降低IO的影响；hash,set，zset，list量过多，将元素进行拆分；删除大key时不用delete，这是一个阻塞的命令删除时会影响性能，使用lazy delete删除指定的key，如果不存在则跳过，非阻塞；
    热key： 指有大量的请求，几十万的访问某一个redis，某个key，集中访问达到网络上限，导致redis服务器延机，将直接访问数据库，造成数据库的崩溃，或者访问数据库回填list,在访问数据库，再崩溃；
        如：火爆新闻，秒杀商品；
        如何找到： 可以通过大数据领域的流式计算技术来进行实时数据访问统计，如Strom, Spark, Streaming, Flink;发现热点数据，放入zookeeper进行分析。
        发现热key后直接加载到本地缓存当中，使用easyCache, 系统在获得热点时直接访问缓存，要求数据非常一致的情况下；
        2. 或者在每一个redis主节点中备份热点数据，在读取时，随机读取，将访问压力负载到每个节点上；
        3. 利用对热点数据访问的限流，熔断保护，每个系统实例每秒最多请求缓存集群读取的操作数不要超过400次，超过就熔断掉，不让请求缓存到集群，返回空白啥的，首页主要页面就算了；

9. 缓存数据库不一致时，会造成什么，如何解决？什么是数据并发竞争，会造成什么，如何解决？
    数据源不一致，强一致性是比较困难的，互联网数据处理的特点， 高吞吐量，低延时， 数据敏感性低于金融行业；
    使用时序控制，先更新，在更新，是不能成功的，因为不是原子性；
    我们是使用延时双删，保障数据的最终一致性，1. 在更新数据库时，先删除缓存向，等读的时候再填充缓存；2. 设置2s后删除一次缓存向； 3. 设置缓存过期的时间10s或者1h,尽量短一些；4. 将缓存删除失败的记录到日志中，利用脚步提取记录，再次删除；
    通过数据库的binlog来异步淘汰key, 利用canel,来将binlog日志采集发送到MQ中，然后通过ACK 机制确认删除缓存；
    ACK 机制是消费者从Ribbit MQ中收到消息并处理完成后，反馈给RMQ, RMQ 收到反馈后才将此消息从队列中删除

    数据并发竞争是指： 多个redis的客户端, 同时进行set 同一个key，引发的并发问题，多个客户端-jedis,同时并发写一个Key, 的时候，一个key, 本来顺序变化是 2 -> 3 -> 4; 并发竞争就可能导致，修改的顺序变为，4 -> 3 -> 2;
     解决方案（根本就是进行串行化）： 1. 使用分布式锁，以及时间挫， 保障最终一致性。
              2. 利用消息队列， 将操作进行串行化；

    redis分布式锁
10. 单线程的redis, 为什么这么快？
    1. redis 是在内存中操作，其持久化只是数据的备份，正常情况下，内存与硬盘不会频繁的交换；
    2. 使用多机主从时，采用集群的数据进行扩展的方式；
    3. 我们最大内存设置
    4. 淘汰策略
    5. 数据结构相对简单，有专门的压缩处理；
    6. 单线程没有锁，没有多线程切换调度，不会死锁；
    7. IO多路复用器模型，应用层上的非阻塞的IO
    8. 构建多种通信的模式
    9. 持久化时会使用子进程，不影响主进程。